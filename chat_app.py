import json
import pickle
import faiss
import numpy as np
import requests
from zenml.client import Client
from sentence_transformers import SentenceTransformer

EMBEDDING_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
OLLAMA_URL = "http://localhost:11434/api/chat"
LLM_MODEL = "qwen2:1.5b" 

class Colors:
    HACIVAT = '\033[94m'
    KARAGOZ = '\033[91m'
    RESET = '\033[0m'

def load_resources_from_zenml():
    print("ğŸŒ ZenML sunucusuna baÄŸlanÄ±lÄ±yor...", end=" ", flush=True)
    client = Client()
    
    try:
        
        pipeline_run = client.get_pipeline("rag_ingestion_pipeline").last_successful_run
        
        
        step_name = "create_index_step"
        step = pipeline_run.steps[step_name]
        
        
        if isinstance(step.outputs["output_0"], list):
            serialized_index = step.outputs["output_0"][0].load()
        else:
            serialized_index = step.outputs["output_0"].load()
            
        
        if isinstance(step.outputs["output_1"], list):
            chunks = step.outputs["output_1"][0].load()
        else:
            chunks = step.outputs["output_1"].load()
        
        
        index_bytes = pickle.loads(serialized_index)
        index_arr = np.frombuffer(index_bytes, dtype='uint8')
        index = faiss.deserialize_index(index_arr)
        
        print("BaÅŸarÄ±lÄ±!")
        print(f"ğŸ“¥ {len(chunks)} satÄ±rlÄ±k bilgi hafÄ±zadan Ã§ekildi.")
        
        return index, chunks
        
    except Exception as e:
        print(f"\n HATA: Veri Ã§ekilemedi.\nDetay: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def get_ollama_response(question, context, history):
    system_prompt = (
        "Sen kesinlikle bir yapay zeka deÄŸilsin. Sen geleneksel TÃ¼rk gÃ¶lge oyunu karakterleri Hacivat ve KaragÃ¶z'sÃ¼n. "
        "Asla 'ben bir modelim' veya 'yardÄ±mcÄ± olabilirim' gibi robotik cÃ¼mleler kurma. "
        "Eski Ä°stanbul aÄŸzÄ±yla, komik, kinayeli ve atÄ±ÅŸmalÄ± konuÅŸ. "
        "KaragÃ¶z her ÅŸeyi yanlÄ±ÅŸ anlasÄ±n. Hacivat ise kibar ve bilgili olsun. "
        "Verilen baÄŸlamÄ± (Context) kullanarak cevap ver ama baÄŸlamda bilgi yoksa doÄŸaÃ§lama yap. "
        "CevabÄ± sadece tiyatro metni formatÄ±nda ver (HACÄ°VAT: ... KARAGÃ–Z: ...)."
    )
    
    messages = [{"role": "system", "content": system_prompt}]
    
    messages.extend(history[-4:]) 
    
    user_input = f"BAÄLAM:\n{context}\n\nKULLANICI SORUSU: {question}"
    messages.append({"role": "user", "content": user_input})
    
    payload = {"model": LLM_MODEL, "messages": messages, "stream": True}
    
    print(f"\n{Colors.HACIVAT}ğŸ­ Sahne:{Colors.RESET}")
    full_text = ""
    try:
        with requests.post(OLLAMA_URL, json=payload, stream=True) as r:
            for line in r.iter_lines():
                if line:
                    body = json.loads(line)
                    content = body.get("message", {}).get("content", "")
                    print(content, end="", flush=True)
                    full_text += content
    except Exception as e:
        print(f"Ollama HatasÄ±: {e}")
        return "Hata oluÅŸtu."
        
    print("\n" + "-"*50)
    return full_text

def main():
    
    index, chunks = load_resources_from_zenml()
    if not index: return

    
    print("ğŸ§  Embedding modeli yÃ¼kleniyor...", end=" ")
    emb_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    print("Tamam.")
    
    chat_history = []
    print("\n" + "="*40)
    print("ğŸ­ HACÄ°VAT VE KARAGÃ–Z Ä°LE SOHBET ğŸ­")
    print("   (Ã‡Ä±kmak iÃ§in 'q' yazÄ±n)")
    print("="*40 + "\n")

    while True:
        try:
            soru = input(f"{Colors.KARAGOZ}Siz:{Colors.RESET} ")
            if soru.lower() in ["q", "exit", "Ã§Ä±kÄ±ÅŸ"]: 
                print("Haydi bana mÃ¼saade!")
                break
            
            if not soru.strip(): continue
            
    
            q_vec = emb_model.encode([soru]).astype('float32')
            _, I = index.search(q_vec, k=3)
            
    
            context = "\n".join([chunks[i] for i in I[0]])
            
    
            cevap = get_ollama_response(soru, context, chat_history)
            
            chat_history.append({"role": "user", "content": soru})
            chat_history.append({"role": "assistant", "content": cevap})
            
        except KeyboardInterrupt:
            print("\nÃ‡Ä±kÄ±ÅŸ yapÄ±lÄ±yor...")
            break

if __name__ == "__main__":
    main()